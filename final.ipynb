{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zm3DQCxL7jUt","executionInfo":{"status":"ok","timestamp":1627297426433,"user_tz":-480,"elapsed":2058,"user":{"displayName":"Gary Zhang","photoUrl":"","userId":"06596158190416046048"}},"outputId":"7cdb456c-414c-48bd-c2b2-a6a63b4ed841"},"source":["!git clone https://bitbucket.org/ctank/swsbackend.git\n","!cp swsbackend/uri.py ./\n","!cp swsbackend/codes.py ./\n","!cp swsbackend/client.py ./\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'swsbackend'...\n","Receiving objects: 100% (265/265), 875.59 KiB | 8.26 MiB/s, done.\n","Resolving deltas: 100% (145/145), done.\n","client.py  codes.py  sample_data  swsbackend  uri.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p4o3EPdy6X5Y","executionInfo":{"status":"ok","timestamp":1627297731152,"user_tz":-480,"elapsed":22461,"user":{"displayName":"Gary Zhang","photoUrl":"","userId":"06596158190416046048"}},"outputId":"a6389cce-8b02-4878-b56a-3cd5ac7ddcfc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zOWxxs-mRDYj"},"source":["# 1 Data Collection"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVMajU5g8Kuw","executionInfo":{"elapsed":130789,"status":"ok","timestamp":1627223091704,"user":{"displayName":"Gary Zhang","photoUrl":"","userId":"06596158190416046048"},"user_tz":-480},"outputId":"39386238-64a4-461d-fa60-f05d2d2f2d75"},"source":["import client\n","import csv\n","import datetime\n","import pandas as pd\n","import numpy as np\n","\n","# Log in to the client\n","\n","client.login('sws3009', 'mongobongo')\n","\n","# Download the data\n","resp = client.find_data(username='sws30095')\n","\n","# Write the data as a CSV file to weather.csv\n","csv_header = [\"timetstamp\", \"user\", \"lon\", \"lat\", \"humid\", \"temp\", \"soil_humid\", \"img_raw\", \"weather\"]\n","\n","print(\"\\nWriting to weather_final.csv\\n\")\n","with open(\"/content/drive/MyDrive/SWS/final/weather_final_5.csv\", \"w\") as f:\n","    writer = csv.writer(f)\n","    writer.writerow(csv_header)\n","    \n","    for data in resp['data']:\n","\n","        # Convert timestamp back to string\n","        timestamp = datetime.datetime.strftime(data['timestamp'], '%d:%m:%Y:%H:%M:%S')\n","        # img_raw_bytes = bytes(data['raw'], encoding='utf8')\n","        if data['raw']!='':\n","          writer.writerow([timestamp, data['username'], data['loc'][0],  data['loc'][1],  data['humid'], data['temp'], data['light'], [data['raw']],\n","              data['rain']])\n","        \n","print(\"Done!\\n\")\n","        "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Writing to weather_final.csv\n","\n","Done!\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zr0_Wxh1RJfc"},"source":["# 2 Data Preparation"]},{"cell_type":"code","metadata":{"id":"9gBUVNNKOPmy"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","from PIL import Image\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","\n","TRAIN_PERCENT = 0.8\n","LOOK_BACK = 10\n","num_epochs = 5\n","batch_size = 1\n","hidden_size = 128\n","skip = 1\n","MODEL_NAME = 'weather_pred_cpu.hd5'\n","# PATH = Path('/content/drive/MyDrive/SWS/final')\n","\n","\n","def imgFromBytes2Array(img_raw):\n","  img_raw_data = eval(img_raw)[0]\n","  img = Image.frombytes(\"RGB\", (400, 225), img_raw_data)\n","  img = img.resize((150, 150))\n","  img_array = np.array(img)\n","  return img_array\n","\n","# Generate the datasets with the given look_back.\n","def create_dataset(dataset_X_num, dataset_X_img, dataset_Y, look_back=10):\n","    dataX_num, dataX_img, dataY = [], [], []\n","\n","    for i in range(len(dataset_X_num) - look_back - 1):\n","        a = dataset_X_num[i:(i+look_back), :]\n","        b = dataset_X_img[i:(i+look_back), :]\n","        dataX_num.append(a)\n","        dataX_img.append(b)\n","        dataY.append(dataset_Y[i + look_back, :])\n","    return np.array(dataX_num), np.array(dataX_img), np.array(dataY)\n","\n","\n","def load_data():\n","  df_1 = pd.read_csv('/content/drive/MyDrive/SWS/final/weather_final_1.csv')\n","  df_2 = pd.read_csv('/content/drive/MyDrive/SWS/final/weather_final_2.csv')\n","  # df_3 = pd.read_csv('/content/drive/MyDrive/SWS/final/weather_final_3.csv')\n","  # df_4 = pd.read_csv('/content/drive/MyDrive/SWS/final/weather_final_4.csv')\n","  df_5 = pd.read_csv('/content/drive/MyDrive/SWS/final/weather_final_5.csv')\n","  df = pd.concat([df_1, df_2, df_5], axis = 0)\n","  df['img'] = df['img_raw'].apply(imgFromBytes2Array)\n","\n","  num_X = np.array(df[['humid', 'temp', 'soil_humid']]).astype('float32')\n","  scaler = MinMaxScaler(feature_range = (0, 1))\n","  num_X = scaler.fit_transform(num_X)\n","\n","  img_X = np.array(df['img'].tolist()) / 255.0\n","  y = to_categorical(df['weather'], 3)\n","\n","  # Call create_dataset to make the training and testing sets.\n","  num_X, img_X, y = create_dataset(num_X, img_X, y, LOOK_BACK)\n","\n","  # Figure out how many vectors for training and how many for\n","  # testing.\n","  train_size = int(len(num_X) * TRAIN_PERCENT)\n","  val_size = len(num_X) - train_size\n","  # Slice the dataset accordingly\n","\n","  # train_X_img, val_X_img = img_X, img_X[train_size: ]\n","  # train_X_num, val_X_num = num_X, num_X[train_size: ]\n","  # train_X_img, val_X_img = img_X[: train_size], img_X[train_size: ]\n","  # train_X_num, val_X_num = num_X[: train_size], num_X[train_size: ]\n","  # train_y, val_y = y, y[train_size: ]\n","  # train_y, val_y = y[: train_size], y[train_size: ]\n","  train_X_img, val_X_img, train_y, val_y = train_test_split(img_X, y, test_size=0.2, random_state=1)\n","  train_X_num, val_X_num, train_y, val_y = train_test_split(num_X, y, test_size=0.2, random_state=1)\n","\n","  return train_X_num, train_X_img, train_y, val_X_num, val_X_img, val_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"02YivCSkX8NA"},"source":["print(train_X_num.shape)\n","print(train_X_img.shape)\n","print(train_y.shape)\n","print(val_X_num.shape)\n","print(val_X_img.shape)\n","print(val_y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Snjmu1jQ1nw"},"source":["\n","# shape[0] gives # of rows, shape[1] gives number of columns.\n","# So here we have shape[0] rows each of 1 input of shape[1] columns.\n","# Number of columns is our lookback.\n","\n","# train_X_num = np.reshape(train_X_num, (train_X_num.shape[0], 3, train_X_num.shape[1]))\n","# val_X_num = np.reshape(val_X_num, (val_X_num.shape[0], 3, val_X_num.shape[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Us5IorOu1nK6"},"source":["from keras.layers import LSTM, Dense, Conv2D, Input, Flatten, TimeDistributed, MaxPooling2D, concatenate\n","from keras.models import Sequential, Model, load_model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","def weatherPredModel(model_name):\n","  if os.path.exists(model_name):\n","    model = load_model(model_name)  \n","\n","  else:  \n","\n","    # define two sets of inputs\n","    input_num = Input(shape=(None, 3))\n","    input_img = Input(shape=(None, 150, 150, 3))\n","    \n","    Conv_1 = TimeDistributed(Conv2D(25, 12, strides=(2, 2), padding='valid', activation='relu'))(input_img)\n","    Pool_1 = TimeDistributed(MaxPooling2D(pool_size=(2,2)))(Conv_1)\n","    Flatten_1 = TimeDistributed(Flatten())(Pool_1)\n","    d = Dense(3)(Flatten_1)\n","    cnn_model = Model(inputs=input_img, outputs=d)\n","\n","    Dense_2 = TimeDistributed(Dense(1024, activation='relu'))(input_num)\n","    mlp_model = Model(inputs=input_num, outputs=Dense_2)\n","\n","    input_combined = concatenate([mlp_model.output, cnn_model.output])\n","    LSTM_1 = LSTM(hidden_size)(input_combined)\n","    y = Dense(3, activation='softmax')(LSTM_1)\n","\n","    model = Model(inputs=[mlp_model.input, cnn_model.input], outputs=y)\n","\n","  return model\n","\n","def train(model, train_X_num, train_X_img, train_y,  val_X_num, val_X_img, val_y, epoch, model_name):\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  # Print a summary of our network\n","  savemodel = ModelCheckpoint(model_name)\n","  stopmodel = EarlyStopping(min_delta=0.001, patience=10) \n","\n","  #Start training\n","  model.fit([train_X_num, train_X_img], train_y, epochs=num_epochs, validation_data = ([val_X_num, val_X_img], val_y), callbacks=[savemodel, stopmodel])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzRybwjCZ-x0","executionInfo":{"elapsed":573892,"status":"ok","timestamp":1627295085716,"user":{"displayName":"Gary Zhang","photoUrl":"","userId":"06596158190416046048"},"user_tz":-480},"outputId":"180d6c65-f4db-4d2c-e44c-428bcf894578"},"source":["train_X_num, train_X_img, train_y, val_X_num, val_X_img, val_y = load_data()\n","model = weatherPredModel(MODEL_NAME)\n","train(model, train_X_num, train_X_img, train_y, val_X_num, val_X_img, val_y, num_epochs, MODEL_NAME)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","20/20 [==============================] - 107s 4s/step - loss: 0.8688 - accuracy: 0.5632 - val_loss: 0.3101 - val_accuracy: 0.8039\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/5\n","20/20 [==============================] - 81s 4s/step - loss: 0.3388 - accuracy: 0.8548 - val_loss: 0.0495 - val_accuracy: 0.9935\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 3/5\n","20/20 [==============================] - 82s 4s/step - loss: 0.1240 - accuracy: 0.9566 - val_loss: 0.0302 - val_accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 4/5\n","20/20 [==============================] - 82s 4s/step - loss: 0.0898 - accuracy: 0.9815 - val_loss: 0.0372 - val_accuracy: 0.9935\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 5/5\n","20/20 [==============================] - 82s 4s/step - loss: 0.0712 - accuracy: 0.9826 - val_loss: 0.0356 - val_accuracy: 1.0000\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: weather_pred_cpu.hd5/assets\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"dG8042yezsr3"},"source":["cp -r weather_pred_cpu.hd5 /content/drive/MyDrive/SWS/final"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r-fBJp6G5XRB"},"source":["def create_cnn(width, height, depth, filters=(16, 32, 64), regress=False):\n","\t# initialize the input shape and channel dimension, assuming\n","\t# TensorFlow/channels-last ordering\n","\tinputShape = (height, width, depth)\n","\tchanDim = -1\n","\t\n","\t# define the model input\n","\tinputs = Input(shape=inputShape)\n"," \n","\t# loop over the number of filters\n","\tfor (i, f) in enumerate(filters):\n","\t\t# if this is the first CONV layer then set the input\n","\t\t# appropriately\n","\t\tif i == 0:\n","\t\t\tx = inputs\n"," \n","\t\t# CONV => RELU => BN => POOL\n","\t\tx = Conv2D(f, (3, 3), padding=\"same\")(x)\n","\t\tx = Activation(\"relu\")(x)\n","\t\tx = BatchNormalization(axis=chanDim)(x)\n","\t\tx = MaxPooling2D(pool_size=(2, 2))(x)\n","\t# flatten the volume, then FC => RELU => BN => DROPOUT\n","\tx = Flatten()(x)\n","\tx = Dense(16)(x)\n","\tx = Activation(\"relu\")(x)\n","\tx = BatchNormalization(axis=chanDim)(x)\n","\tx = Dropout(0.5)(x)\n"," \n","\t# apply another FC layer, this one to match the number of nodes\n","\t# coming out of the MLP\n","\tx = Dense(4)(x)\n","\tx = Activation(\"relu\")(x)\n"," \n","\t# check to see if the regression node should be added\n","\tif regress:\n","\t\tx = Dense(1, activation=\"linear\")(x)\n"," \n","\t# construct the CNN\n","\tmodel = Model(inputs, x)\n"," \n","\t# return the CNN\n","\treturn model\n"],"execution_count":null,"outputs":[]}]}